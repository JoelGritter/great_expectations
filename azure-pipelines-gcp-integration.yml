stages:
  - stage: instantiate_composer_and_install_ge
    pool:
      vmImage: 'ubuntu-latest'
    jobs:
    - job: composer_ge_install
      timeoutInMinutes: 60 # this should be more than sufficient since the performance typically runs < 5 min
      steps:
        - bash: echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
          displayName: 'install gcloud 1 - adding URI as package source'
        - bash: curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
          displayName: 'install gcloud 2 - import Google Cloud public key'
        - bash: sudo snap install google-cloud-cli
          displayName: 'install gcloud 3 - update and install gcloud CLI'

        # - script: |
        #     pip install google-cloud-bigquery-storage
        #   displayName: 'Install Google Cloud dependencies'
        # - task: DownloadSecureFile@1
        #   name: gcp_authkey
        #   displayName: 'Download Google Service Account'
        #   inputs:
        #     secureFile: 'superconductive-service-acct_ge-oss-ci-cd.json'
        #     retryCount: '2'
        #
        # - bash: gcloud composer environments create composer-1-temporary-env --location=us-east1 --zone=us-east1-b --machine-type=n1-standard-8
        #   displayName: 'spin up Google Composer environment'
        #   env:
        #     GOOGLE_APPLICATION_CREDENTIALS: $(gcp_authkey.secureFilePath)
        #     GE_TEST_GCP_PROJECT: $(GE_TEST_GCP_PROJECT)
        #     GE_TEST_BIGQUERY_DATASET: $(GE_TEST_BIGQUERY_DATASET)
        #     GE_TEST_BIGQUERY_PERFORMANCE_DATASET: $(GE_TEST_BIGQUERY_PERFORMANCE_DATASET)


    # jobs:
    #   - job: bigquery_performance_test
    #     timeoutInMinutes: 30 # this should be more than sufficient since the performance typically runs < 5 min
    #     variables:
    #       python.version: '3.8'
    #
    #     strategy:
    #       matrix:
    #         performance:
    #           test_script: 'tests/performance/test_bigquery_benchmarks.py'
    #           extra_args: '--bigquery --performance-tests --benchmark-json=junit/benchmark.json -k test_taxi_trips_benchmark[1-True-V3] '
    #       maxParallel: 1
    #
    #     steps:
    #       - task: UsePythonVersion@0
    #         inputs:
    #           versionSpec: '$(python.version)'
    #         displayName: 'Use Python $(python.version)'
    #
    #       - bash: python -m pip install --upgrade pip==20.2.4
    #         displayName: 'Update pip'
    #
    #       - script: |
    #           pip install -r requirements-dev.txt --constraint constraints-dev.txt
    #         displayName: 'Install dependencies'
    #       - script: |
    #           pip install google-cloud-bigquery-storage
    #         displayName: 'Install Google Cloud dependencies'
    #       - task: DownloadSecureFile@1
    #         name: gcp_authkey
    #         displayName: 'Download Google Service Account'
    #         inputs:
    #           secureFile: 'superconductive-service-acct_ge-oss-ci-cd.json'
    #           retryCount: '2'
    #
    #       - script: |
    #           pip install pytest-azurepipelines
    #           pip freeze > pip-freeze.txt
    #           mkdir -p junit
    #           pytest -v $(test_script) \
    #             $(extra_args) \
    #             --bigquery \
    #             --junitxml=junit/test-results.xml \
    #              --napoleon-docstrings --cov=. --cov-report=xml --cov-report=html \
    #             --ignore=tests/cli --ignore=tests/integration/usage_statistics
    #         displayName: 'pytest'
    #         env:
    #           GOOGLE_APPLICATION_CREDENTIALS: $(gcp_authkey.secureFilePath)
    #           GE_TEST_GCP_PROJECT: $(GE_TEST_GCP_PROJECT)
    #           GE_TEST_BIGQUERY_DATASET: $(GE_TEST_BIGQUERY_DATASET)
    #           GE_TEST_BIGQUERY_PERFORMANCE_DATASET: $(GE_TEST_BIGQUERY_PERFORMANCE_DATASET)
    #       - task: PublishTestResults@2
    #         inputs:
    #           searchFolder: junit
    #           testResultsFiles: test-results.xml
    #
    #       - publish: junit/benchmark.json
    #         artifact: BenchmarkResult
    #
    #       # The pip freeze output could be helpful to reproduce performance test results.
    #       - publish: pip-freeze.txt
    #         artifact: PipFreeze
    #
    #   - job: bigquery_expectations_test
    #     timeoutInMinutes: 150 # Each stage runs in about 60 min and 30 min respectively.
    #     variables:
    #       python.version: '3.8'
    #
    #     strategy:
    #       matrix:
    #         expectations_cfe:
    #           test_script: 'tests/test_definitions/test_expectations_cfe.py'
    #           extra_args: ''
    #         expectations:
    #           test_script: 'tests/test_definitions/test_expectations.py'
    #           extra_args: ''
    #       maxParallel: 1
    #     steps:
    #       - task: UsePythonVersion@0
    #         inputs:
    #           versionSpec: '$(python.version)'
    #         displayName: 'Use Python $(python.version)'
    #
    #       - bash: python -m pip install --upgrade pip==20.2.4
    #         displayName: 'Update pip'
    #
    #       - script: |
    #           pip install -r requirements-dev.txt --constraint constraints-dev.txt
    #         displayName: 'Install dependencies'
    #       - script: |
    #           pip install google-cloud-bigquery-storage
    #         displayName: 'Install Google Cloud dependencies'
    #       - task: DownloadSecureFile@1
    #         name: gcp_authkey
    #         displayName: 'Download Google Service Account'
    #         inputs:
    #           secureFile: 'superconductive-service-acct_ge-oss-ci-cd.json'
    #           retryCount: '2'
    #
    #       - script: |
    #           pip install pytest-azurepipelines
    #           pip freeze > pip-freeze.txt
    #           mkdir -p junit
    #           pytest -v $(test_script) \
    #             $(extra_args) \
    #             --bigquery \
    #             --junitxml=junit/test-results.xml \
    #             --napoleon-docstrings --cov=. --cov-report=xml --cov-report=html \
    #             --ignore=tests/cli --ignore=tests/integration/usage_statistics
    #         displayName: 'pytest'
    #         env:
    #           GOOGLE_APPLICATION_CREDENTIALS: $(gcp_authkey.secureFilePath)
    #           GE_TEST_GCP_PROJECT: $(GE_TEST_GCP_PROJECT)
    #           GE_TEST_BIGQUERY_DATASET: $(GE_TEST_BIGQUERY_DATASET)
    #       # The pip freeze output could be helpful to reproduce performance test results.
    #       - publish: pip-freeze.txt
    #         artifact: PipFreeze
